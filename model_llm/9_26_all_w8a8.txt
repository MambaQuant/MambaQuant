model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_easy, w8a8_method_0.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.4230|±  |0.0101|
|        |       |none  |     0|acc_norm|↑  |0.3758|±  |0.0099|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_challenge, w8a8_method_0.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2363|±  |0.0124|
|             |       |none  |     0|acc_norm|↑  |0.2577|±  |0.0128|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: piqa, w8a8_method_0.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.5827|±  |0.0115|
|     |       |none  |     0|acc_norm|↑  |0.5778|±  |0.0115|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: winogrande, w8a8_method_0.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5083|±  |0.0141|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: hellaswag, w8a8_method_0.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3038|±  |0.0046|
|         |       |none  |     0|acc_norm|↑  |0.3377|±  |0.0047|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_easy, w8a8_method_1
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.4234|±  |0.0101|
|        |       |none  |     0|acc_norm|↑  |0.3948|±  |0.0100|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_challenge, w8a8_method_1
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2184|±  |0.0121|
|             |       |none  |     0|acc_norm|↑  |0.2509|±  |0.0127|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: piqa, w8a8_method_1
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.5941|±  |0.0115|
|     |       |none  |     0|acc_norm|↑  |0.5849|±  |0.0115|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: winogrande, w8a8_method_1
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5036|±  |0.0141|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: hellaswag, w8a8_method_1
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3042|±  |0.0046|
|         |       |none  |     0|acc_norm|↑  |0.3390|±  |0.0047|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_easy, w8a8_method_1.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.4402|±  |0.0102|
|        |       |none  |     0|acc_norm|↑  |0.3977|±  |0.0100|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_challenge, w8a8_method_1.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.1980|±  |0.0116|
|             |       |none  |     0|acc_norm|↑  |0.2474|±  |0.0126|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: piqa, w8a8_method_1.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6028|±  |0.0114|
|     |       |none  |     0|acc_norm|↑  |0.6001|±  |0.0114|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: winogrande, w8a8_method_1.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5107|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: hellaswag, w8a8_method_1.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3046|±  |0.0046|
|         |       |none  |     0|acc_norm|↑  |0.3450|±  |0.0047|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_easy, w8a8_method_2
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.4592|±  |0.0102|
|        |       |none  |     0|acc_norm|↑  |0.4070|±  |0.0101|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: arc_challenge, w8a8_method_2
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2039|±  |0.0118|
|             |       |none  |     0|acc_norm|↑  |0.2423|±  |0.0125|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: piqa, w8a8_method_2
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6246|±  |0.0113|
|     |       |none  |     0|acc_norm|↑  |0.6186|±  |0.0113|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: winogrande, w8a8_method_2
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5225|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf, task: hellaswag, w8a8_method_2
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-130m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3089|±  |0.0046|
|         |       |none  |     0|acc_norm|↑  |0.3473|±  |0.0048|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_easy, w8a8_method_0.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.5046|±  |0.0103|
|        |       |none  |     0|acc_norm|↑  |0.4588|±  |0.0102|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_challenge, w8a8_method_0.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2440|±  |0.0126|
|             |       |none  |     0|acc_norm|↑  |0.2875|±  |0.0132|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: piqa, w8a8_method_0.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6496|±  |0.0111|
|     |       |none  |     0|acc_norm|↑  |0.6436|±  |0.0112|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: winogrande, w8a8_method_0.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5012|±  |0.0141|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: hellaswag, w8a8_method_0.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3653|±  |0.0048|
|         |       |none  |     0|acc_norm|↑  |0.4509|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_easy, w8a8_method_1
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.5084|±  |0.0103|
|        |       |none  |     0|acc_norm|↑  |0.4562|±  |0.0102|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_challenge, w8a8_method_1
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2602|±  |0.0128|
|             |       |none  |     0|acc_norm|↑  |0.2892|±  |0.0133|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: piqa, w8a8_method_1
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6578|±  |0.0111|
|     |       |none  |     0|acc_norm|↑  |0.6610|±  |0.0110|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: winogrande, w8a8_method_1
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5367|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: hellaswag, w8a8_method_1
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3628|±  |0.0048|
|         |       |none  |     0|acc_norm|↑  |0.4560|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_easy, w8a8_method_1.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.4992|±  |0.0103|
|        |       |none  |     0|acc_norm|↑  |0.4512|±  |0.0102|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_challenge, w8a8_method_1.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2713|±  |0.0130|
|             |       |none  |     0|acc_norm|↑  |0.2935|±  |0.0133|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: piqa, w8a8_method_1.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6540|±  |0.0111|
|     |       |none  |     0|acc_norm|↑  |0.6605|±  |0.0110|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: winogrande, w8a8_method_1.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5367|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: hellaswag, w8a8_method_1.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3647|±  |0.0048|
|         |       |none  |     0|acc_norm|↑  |0.4605|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_easy, w8a8_method_2
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.5105|±  |0.0103|
|        |       |none  |     0|acc_norm|↑  |0.4520|±  |0.0102|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: arc_challenge, w8a8_method_2
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2551|±  |0.0127|
|             |       |none  |     0|acc_norm|↑  |0.2901|±  |0.0133|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: piqa, w8a8_method_2
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6697|±  | 0.011|
|     |       |none  |     0|acc_norm|↑  |0.6605|±  | 0.011|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: winogrande, w8a8_method_2
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5233|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf, task: hellaswag, w8a8_method_2
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3688|±  |0.0048|
|         |       |none  |     0|acc_norm|↑  |0.4536|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_easy, w8a8_method_0.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.5274|±  |0.0102|
|        |       |none  |     0|acc_norm|↑  |0.4777|±  |0.0102|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_challenge, w8a8_method_0.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2688|±  |0.0130|
|             |       |none  |     0|acc_norm|↑  |0.3174|±  |0.0136|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: piqa, w8a8_method_0.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6447|±  |0.0112|
|     |       |none  |     0|acc_norm|↑  |0.6502|±  |0.0111|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: winogrande, w8a8_method_0.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5359|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: hellaswag, w8a8_method_0.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3944|±  |0.0049|
|         |       |none  |     0|acc_norm|↑  |0.5143|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_easy, w8a8_method_1
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.5236|±  |0.0102|
|        |       |none  |     0|acc_norm|↑  |0.4848|±  |0.0103|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_challenge, w8a8_method_1
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2901|±  |0.0133|
|             |       |none  |     0|acc_norm|↑  |0.3234|±  |0.0137|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: piqa, w8a8_method_1
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6404|±  |0.0112|
|     |       |none  |     0|acc_norm|↑  |0.6507|±  |0.0111|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: winogrande, w8a8_method_1
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5501|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: hellaswag, w8a8_method_1
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3951|±  |0.0049|
|         |       |none  |     0|acc_norm|↑  |0.5185|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_easy, w8a8_method_1.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.5417|±  |0.0102|
|        |       |none  |     0|acc_norm|↑  |0.4987|±  |0.0103|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_challenge, w8a8_method_1.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2679|±  |0.0129|
|             |       |none  |     0|acc_norm|↑  |0.3089|±  |0.0135|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: piqa, w8a8_method_1.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6583|±  |0.0111|
|     |       |none  |     0|acc_norm|↑  |0.6725|±  |0.0109|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: winogrande, w8a8_method_1.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5533|±  | 0.014|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: hellaswag, w8a8_method_1.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.3997|±  |0.0049|
|         |       |none  |     0|acc_norm|↑  |0.5199|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_easy, w8a8_method_2
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.5530|±  |0.0102|
|        |       |none  |     0|acc_norm|↑  |0.4992|±  |0.0103|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: arc_challenge, w8a8_method_2
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2662|±  |0.0129|
|             |       |none  |     0|acc_norm|↑  |0.2944|±  |0.0133|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: piqa, w8a8_method_2
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.6872|±  |0.0108|
|     |       |none  |     0|acc_norm|↑  |0.6893|±  |0.0108|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: winogrande, w8a8_method_2
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5612|±  |0.0139|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf, task: hellaswag, w8a8_method_2
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-790m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.4017|±  |0.0049|
|         |       |none  |     0|acc_norm|↑  |0.5290|±  |0.0050|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_easy, w8a8_method_0.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.6170|±  |0.0100|
|        |       |none  |     0|acc_norm|↑  |0.5825|±  |0.0101|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_challenge, w8a8_method_0.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2901|±  |0.0133|
|             |       |none  |     0|acc_norm|↑  |0.3174|±  |0.0136|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: piqa, w8a8_method_0.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.7002|±  |0.0107|
|     |       |none  |     0|acc_norm|↑  |0.7040|±  |0.0107|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: winogrande, w8a8_method_0.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5809|±  |0.0139|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: hellaswag, w8a8_method_0.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.4394|±  |0.0050|
|         |       |none  |     0|acc_norm|↑  |0.5747|±  |0.0049|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_easy, w8a8_method_1
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.6077|±  |0.0100|
|        |       |none  |     0|acc_norm|↑  |0.5720|±  |0.0102|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_challenge, w8a8_method_1
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.3003|±  |0.0134|
|             |       |none  |     0|acc_norm|↑  |0.3268|±  |0.0137|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: piqa, w8a8_method_1
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.7084|±  |0.0106|
|     |       |none  |     0|acc_norm|↑  |0.7127|±  |0.0106|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: winogrande, w8a8_method_1
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5785|±  |0.0139|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: hellaswag, w8a8_method_1
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.4382|±  |0.0050|
|         |       |none  |     0|acc_norm|↑  |0.5788|±  |0.0049|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_easy, w8a8_method_1.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.6111|±  |0.0100|
|        |       |none  |     0|acc_norm|↑  |0.5791|±  |0.0101|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_challenge, w8a8_method_1.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.3055|±  |0.0135|
|             |       |none  |     0|acc_norm|↑  |0.3251|±  |0.0137|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: piqa, w8a8_method_1.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.7138|±  |0.0105|
|     |       |none  |     0|acc_norm|↑  |0.7116|±  |0.0106|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: winogrande, w8a8_method_1.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5738|±  |0.0139|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: hellaswag, w8a8_method_1.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.4415|±  |0.0050|
|         |       |none  |     0|acc_norm|↑  |0.5795|±  |0.0049|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_easy, w8a8_method_2
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.6271|±  |0.0099|
|        |       |none  |     0|acc_norm|↑  |0.5875|±  |0.0101|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: arc_challenge, w8a8_method_2
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.2910|±  |0.0133|
|             |       |none  |     0|acc_norm|↑  |0.3268|±  |0.0137|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: piqa, w8a8_method_2
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.7225|±  |0.0104|
|     |       |none  |     0|acc_norm|↑  |0.7291|±  |0.0104|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: winogrande, w8a8_method_2
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.5754|±  |0.0139|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf, task: hellaswag, w8a8_method_2
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.4395|±  |0.0050|
|         |       |none  |     0|acc_norm|↑  |0.5805|±  |0.0049|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_easy, w8a8_method_0.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|--------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_easy|      1|none  |     0|acc     |↑  |0.6831|±  |0.0095|
|        |       |none  |     0|acc_norm|↑  |0.6258|±  |0.0099|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_challenge, w8a8_method_0.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |↑  |0.3387|±  |0.0138|
|             |       |none  |     0|acc_norm|↑  |0.3532|±  |0.0140|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: piqa, w8a8_method_0.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|Tasks|Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-----|------:|------|-----:|--------|---|-----:|---|-----:|
|piqa |      1|none  |     0|acc     |↑  |0.7334|±  |0.0103|
|     |       |none  |     0|acc_norm|↑  |0.7394|±  |0.0102|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: winogrande, w8a8_method_0.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|----------|------:|------|-----:|------|---|-----:|---|-----:|
|winogrande|      1|none  |     0|acc   |↑  |0.6022|±  |0.0138|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: hellaswag, w8a8_method_0.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: False
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: False
use_S7: False
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: False
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: minmax
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
mamba (pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 64
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.4835|±  |0.0050|
|         |       |none  |     0|acc_norm|↑  |0.6469|±  |0.0048|

model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_easy, w8a8_method_1
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_challenge, w8a8_method_1
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: piqa, w8a8_method_1
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: winogrande, w8a8_method_1
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: hellaswag, w8a8_method_1
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: False
use_S3: False
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_easy, w8a8_method_1.5
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_challenge, w8a8_method_1.5
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: piqa, w8a8_method_1.5
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: winogrande, w8a8_method_1.5
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: hellaswag, w8a8_method_1.5
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: False
use_hadmard_R3: False
use_hadmard_R4: False
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_easy, w8a8_method_2
model: mamba
tasks: arc_easy
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: arc_challenge, w8a8_method_2
model: mamba
tasks: arc_challenge
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: piqa, w8a8_method_2
model: mamba
tasks: piqa
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: winogrande, w8a8_method_2
model: mamba
tasks: winogrande
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
model: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf, task: hellaswag, w8a8_method_2
model: mamba
tasks: hellaswag
model_args: pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
num_fewshot: None
batch_size: 64
max_batch_size: None
device: cuda
output_path: None
limit: None
use_cache: None
cache_requests: None
check_integrity: False
write_out: False
log_samples: False
system_instruction: None
apply_chat_template: False
fewshot_as_multiturn: False
show_config: False
include_path: None
gen_kwargs: None
verbosity: INFO
wandb_args: 
hf_hub_log_args: 
predict_only: False
seed: [0, 1234, 1234, 1234]
trust_remote_code: False
use_smoothquant: False
use_gptq: False
use_hadmard: True
use_klt: True
use_weight_klt: False
use_S_head: False
use_S1: False
use_S2: True
use_S3: True
use_S4: False
use_S5: True
use_S7: True
use_hadmard_R1: True
use_hadmard_R2: True
use_hadmard_R3: False
use_hadmard_R4: True
use_hadmard_R5: True
use_hadmard_R6: False
use_pertoken: True
static_quant: False
quant_weight: True
quant_act: True
w_bit: 8
a_bit: 8
w_perchannel: True
observe: percentile
fake_online_hadamard: False
use_perkernel: False
use_reduce_mean: False
analyse_and_plot: False
w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
conv1d_w_cfg: {'dynamic_method': 'per_channel', 'per_channel_axes': [0], 'n_bits': 8}
a_cfg: {'dynamic_method': 'per_tensor', 'n_bits': 8}
*************************************
model_path:  pretrained=/data01/home/xuzk/datasets/lm_mamba_weight/mamba-2.8b-hf
*************************************
backbone.layers.0.mixer.in_proj_states input is orthogonal
backbone.layers.0.mixer.in_proj_gates input is orthogonal
backbone.layers.0.mixer.x_proj_dt input is orthogonal
backbone.layers.0.mixer.x_proj_b input is orthogonal
backbone.layers.0.mixer.x_proj_c input is orthogonal
backbone.layers.0.mixer.dt_proj input is orthogonal
backbone.layers.0.mixer.ssm_matmul input is orthogonal
backbone.layers.0.mixer.out_proj input is orthogonal
backbone.layers.1.mixer.in_proj_states input is orthogonal
backbone.layers.1.mixer.in_proj_gates input is orthogonal
backbone.layers.1.mixer.x_proj_dt input is orthogonal
backbone.layers.1.mixer.x_proj_b input is orthogonal
backbone.layers.1.mixer.x_proj_c input is orthogonal
backbone.layers.1.mixer.dt_proj input is orthogonal
backbone.layers.1.mixer.ssm_matmul input is orthogonal
backbone.layers.1.mixer.out_proj input is orthogonal
backbone.layers.2.mixer.in_proj_states input is orthogonal
backbone.layers.2.mixer.in_proj_gates input is orthogonal
backbone.layers.2.mixer.x_proj_dt input is orthogonal
backbone.layers.2.mixer.x_proj_b input is orthogonal
backbone.layers.2.mixer.x_proj_c input is orthogonal
backbone.layers.2.mixer.dt_proj input is orthogonal
backbone.layers.2.mixer.ssm_matmul input is orthogonal
backbone.layers.2.mixer.out_proj input is orthogonal
backbone.layers.3.mixer.in_proj_states input is orthogonal
backbone.layers.3.mixer.in_proj_gates input is orthogonal
backbone.layers.3.mixer.x_proj_dt input is orthogonal
backbone.layers.3.mixer.x_proj_b input is orthogonal
backbone.layers.3.mixer.x_proj_c input is orthogonal
backbone.layers.3.mixer.dt_proj input is orthogonal
backbone.layers.3.mixer.ssm_matmul input is orthogonal
backbone.layers.3.mixer.out_proj input is orthogonal
backbone.layers.4.mixer.in_proj_states input is orthogonal
backbone.layers.4.mixer.in_proj_gates input is orthogonal
backbone.layers.4.mixer.x_proj_dt input is orthogonal
backbone.layers.4.mixer.x_proj_b input is orthogonal
backbone.layers.4.mixer.x_proj_c input is orthogonal
backbone.layers.4.mixer.dt_proj input is orthogonal
backbone.layers.4.mixer.ssm_matmul input is orthogonal
backbone.layers.4.mixer.out_proj input is orthogonal
backbone.layers.5.mixer.in_proj_states input is orthogonal
backbone.layers.5.mixer.in_proj_gates input is orthogonal
backbone.layers.5.mixer.x_proj_dt input is orthogonal
backbone.layers.5.mixer.x_proj_b input is orthogonal
backbone.layers.5.mixer.x_proj_c input is orthogonal
backbone.layers.5.mixer.dt_proj input is orthogonal
backbone.layers.5.mixer.ssm_matmul input is orthogonal
backbone.layers.5.mixer.out_proj input is orthogonal
backbone.layers.6.mixer.in_proj_states input is orthogonal
backbone.layers.6.mixer.in_proj_gates input is orthogonal
backbone.layers.6.mixer.x_proj_dt input is orthogonal
backbone.layers.6.mixer.x_proj_b input is orthogonal
backbone.layers.6.mixer.x_proj_c input is orthogonal
backbone.layers.6.mixer.dt_proj input is orthogonal
backbone.layers.6.mixer.ssm_matmul input is orthogonal
backbone.layers.6.mixer.out_proj input is orthogonal
backbone.layers.7.mixer.in_proj_states input is orthogonal
backbone.layers.7.mixer.in_proj_gates input is orthogonal
backbone.layers.7.mixer.x_proj_dt input is orthogonal
backbone.layers.7.mixer.x_proj_b input is orthogonal
backbone.layers.7.mixer.x_proj_c input is orthogonal
backbone.layers.7.mixer.dt_proj input is orthogonal
backbone.layers.7.mixer.ssm_matmul input is orthogonal
backbone.layers.7.mixer.out_proj input is orthogonal
backbone.layers.8.mixer.in_proj_states input is orthogonal
backbone.layers.8.mixer.in_proj_gates input is orthogonal
backbone.layers.8.mixer.x_proj_dt input is orthogonal
backbone.layers.8.mixer.x_proj_b input is orthogonal
backbone.layers.8.mixer.x_proj_c input is orthogonal
backbone.layers.8.mixer.dt_proj input is orthogonal
backbone.layers.8.mixer.ssm_matmul input is orthogonal
backbone.layers.8.mixer.out_proj input is orthogonal
backbone.layers.9.mixer.in_proj_states input is orthogonal
backbone.layers.9.mixer.in_proj_gates input is orthogonal
backbone.layers.9.mixer.x_proj_dt input is orthogonal
backbone.layers.9.mixer.x_proj_b input is orthogonal
backbone.layers.9.mixer.x_proj_c input is orthogonal
backbone.layers.9.mixer.dt_proj input is orthogonal
backbone.layers.9.mixer.ssm_matmul input is orthogonal
backbone.layers.9.mixer.out_proj input is orthogonal
backbone.layers.10.mixer.in_proj_states input is orthogonal
backbone.layers.10.mixer.in_proj_gates input is orthogonal
backbone.layers.10.mixer.x_proj_dt input is orthogonal
backbone.layers.10.mixer.x_proj_b input is orthogonal
backbone.layers.10.mixer.x_proj_c input is orthogonal
backbone.layers.10.mixer.dt_proj input is orthogonal
backbone.layers.10.mixer.ssm_matmul input is orthogonal
backbone.layers.10.mixer.out_proj input is orthogonal
backbone.layers.11.mixer.in_proj_states input is orthogonal
backbone.layers.11.mixer.in_proj_gates input is orthogonal
backbone.layers.11.mixer.x_proj_dt input is orthogonal
backbone.layers.11.mixer.x_proj_b input is orthogonal
backbone.layers.11.mixer.x_proj_c input is orthogonal
backbone.layers.11.mixer.dt_proj input is orthogonal
backbone.layers.11.mixer.ssm_matmul input is orthogonal
backbone.layers.11.mixer.out_proj input is orthogonal
backbone.layers.12.mixer.in_proj_states input is orthogonal
backbone.layers.12.mixer.in_proj_gates input is orthogonal
backbone.layers.12.mixer.x_proj_dt input is orthogonal
backbone.layers.12.mixer.x_proj_b input is orthogonal
backbone.layers.12.mixer.x_proj_c input is orthogonal
backbone.layers.12.mixer.dt_proj input is orthogonal
backbone.layers.12.mixer.ssm_matmul input is orthogonal
backbone.layers.12.mixer.out_proj input is orthogonal
backbone.layers.13.mixer.in_proj_states input is orthogonal
backbone.layers.13.mixer.in_proj_gates input is orthogonal
backbone.layers.13.mixer.x_proj_dt input is orthogonal
backbone.layers.13.mixer.x_proj_b input is orthogonal
backbone.layers.13.mixer.x_proj_c input is orthogonal
backbone.layers.13.mixer.dt_proj input is orthogonal
backbone.layers.13.mixer.ssm_matmul input is orthogonal
backbone.layers.13.mixer.out_proj input is orthogonal
backbone.layers.14.mixer.in_proj_states input is orthogonal
backbone.layers.14.mixer.in_proj_gates input is orthogonal
backbone.layers.14.mixer.x_proj_dt input is orthogonal
backbone.layers.14.mixer.x_proj_b input is orthogonal
backbone.layers.14.mixer.x_proj_c input is orthogonal
backbone.layers.14.mixer.dt_proj input is orthogonal
backbone.layers.14.mixer.ssm_matmul input is orthogonal
backbone.layers.14.mixer.out_proj input is orthogonal
backbone.layers.15.mixer.in_proj_states input is orthogonal
backbone.layers.15.mixer.in_proj_gates input is orthogonal
backbone.layers.15.mixer.x_proj_dt input is orthogonal
backbone.layers.15.mixer.x_proj_b input is orthogonal
backbone.layers.15.mixer.x_proj_c input is orthogonal
backbone.layers.15.mixer.dt_proj input is orthogonal
backbone.layers.15.mixer.ssm_matmul input is orthogonal
backbone.layers.15.mixer.out_proj input is orthogonal
backbone.layers.16.mixer.in_proj_states input is orthogonal
backbone.layers.16.mixer.in_proj_gates input is orthogonal
backbone.layers.16.mixer.x_proj_dt input is orthogonal
backbone.layers.16.mixer.x_proj_b input is orthogonal
backbone.layers.16.mixer.x_proj_c input is orthogonal
backbone.layers.16.mixer.dt_proj input is orthogonal
backbone.layers.16.mixer.ssm_matmul input is orthogonal
backbone.layers.16.mixer.out_proj input is orthogonal
backbone.layers.17.mixer.in_proj_states input is orthogonal
backbone.layers.17.mixer.in_proj_gates input is orthogonal
backbone.layers.17.mixer.x_proj_dt input is orthogonal
backbone.layers.17.mixer.x_proj_b input is orthogonal
backbone.layers.17.mixer.x_proj_c input is orthogonal
backbone.layers.17.mixer.dt_proj input is orthogonal
backbone.layers.17.mixer.ssm_matmul input is orthogonal
backbone.layers.17.mixer.out_proj input is orthogonal
backbone.layers.18.mixer.in_proj_states input is orthogonal
backbone.layers.18.mixer.in_proj_gates input is orthogonal
backbone.layers.18.mixer.x_proj_dt input is orthogonal
backbone.layers.18.mixer.x_proj_b input is orthogonal
backbone.layers.18.mixer.x_proj_c input is orthogonal
backbone.layers.18.mixer.dt_proj input is orthogonal
backbone.layers.18.mixer.ssm_matmul input is orthogonal
backbone.layers.18.mixer.out_proj input is orthogonal
backbone.layers.19.mixer.in_proj_states input is orthogonal
backbone.layers.19.mixer.in_proj_gates input is orthogonal
backbone.layers.19.mixer.x_proj_dt input is orthogonal
backbone.layers.19.mixer.x_proj_b input is orthogonal
backbone.layers.19.mixer.x_proj_c input is orthogonal
backbone.layers.19.mixer.dt_proj input is orthogonal
backbone.layers.19.mixer.ssm_matmul input is orthogonal
backbone.layers.19.mixer.out_proj input is orthogonal
backbone.layers.20.mixer.in_proj_states input is orthogonal
backbone.layers.20.mixer.in_proj_gates input is orthogonal
backbone.layers.20.mixer.x_proj_dt input is orthogonal
backbone.layers.20.mixer.x_proj_b input is orthogonal
backbone.layers.20.mixer.x_proj_c input is orthogonal
backbone.layers.20.mixer.dt_proj input is orthogonal
backbone.layers.20.mixer.ssm_matmul input is orthogonal
backbone.layers.20.mixer.out_proj input is orthogonal
backbone.layers.21.mixer.in_proj_states input is orthogonal
backbone.layers.21.mixer.in_proj_gates input is orthogonal
backbone.layers.21.mixer.x_proj_dt input is orthogonal
backbone.layers.21.mixer.x_proj_b input is orthogonal
backbone.layers.21.mixer.x_proj_c input is orthogonal
backbone.layers.21.mixer.dt_proj input is orthogonal
backbone.layers.21.mixer.ssm_matmul input is orthogonal
backbone.layers.21.mixer.out_proj input is orthogonal
backbone.layers.22.mixer.in_proj_states input is orthogonal
backbone.layers.22.mixer.in_proj_gates input is orthogonal
backbone.layers.22.mixer.x_proj_dt input is orthogonal
backbone.layers.22.mixer.x_proj_b input is orthogonal
backbone.layers.22.mixer.x_proj_c input is orthogonal
backbone.layers.22.mixer.dt_proj input is orthogonal
